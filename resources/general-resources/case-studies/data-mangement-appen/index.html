<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>Data Management in Language Technology: A Case Study of Appen - LDaCA</title><meta name=Description content="LDaCA team member Rosanna Smith discusses data management in language technology, focusing on projects at tech company Appen."><meta property="og:url" content="https://www.ldaca.edu.au/resources/general-resources/case-studies/data-mangement-appen/">
<meta property="og:site_name" content="LDaCA"><meta property="og:title" content="Data Management in Language Technology: A Case Study of Appen"><meta property="og:description" content="LDaCA team member Rosanna Smith discusses data management in language technology, focusing on projects at tech company Appen."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="resources"><meta property="article:published_time" content="2024-03-22T15:12:12+11:00"><meta property="article:modified_time" content="2024-03-22T15:12:12+11:00"><meta property="og:image" content="https://www.ldaca.edu.au/logo.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://www.ldaca.edu.au/logo.png"><meta name=twitter:title content="Data Management in Language Technology: A Case Study of Appen"><meta name=twitter:description content="LDaCA team member Rosanna Smith discusses data management in language technology, focusing on projects at tech company Appen."><meta name=twitter:site content="@LDaCA_Program"><meta name=application-name content="LDaCA"><meta name=apple-mobile-web-app-title content="LDaCA"><meta name=theme-color content="#e0e0e0"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://www.ldaca.edu.au/resources/general-resources/case-studies/data-mangement-appen/><link rel=prev href=https://www.ldaca.edu.au/resources/general-resources/case-studies/fieldwork-png/><link rel=next href=https://www.ldaca.edu.au/resources/general-resources/case-studies/masters-research-project/><link rel=stylesheet href=/css/style.min.css><link rel=preload href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css></noscript><link rel=preload href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Data Management in Language Technology: A Case Study of Appen","inLanguage":"en-us","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/www.ldaca.edu.au\/resources\/general-resources\/case-studies\/data-mangement-appen\/"},"genre":"resources","wordcount":2486,"url":"https:\/\/www.ldaca.edu.au\/resources\/general-resources\/case-studies\/data-mangement-appen\/","datePublished":"2024-03-22T15:12:12+11:00","dateModified":"2024-03-22T15:12:12+11:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"Language Data Commons of Australia"},"description":"LDaCA team member Rosanna Smith discusses data management in language technology, focusing on projects at tech company Appen."}</script></head><body data-header-desktop=normal data-header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem("theme")?localStorage.getItem("theme")==="dark":"auto"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"auto"==="dark")&&document.body.setAttribute("theme","dark")</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div id=top-banner><p id=banner-title>Language Data Commons of Australia</p><div id=banner-spacer></div><a href=https://data.ldaca.edu.au/ target=_blank class=banner-button>Data Portal</a>
<a href=https://www.atap.edu.au/ target=_blank class=banner-button>ATAP</a>
<a href=https://language-research-technology.github.io/crate-o/#/ target=_blank class=banner-button>Crate-O</a></div><div class=header-wrapper><div class=header-title><a href=/ title=LDaCA><img class="lazyload logo" src=/svg/loading.min.svg data-src=/logo.png data-srcset="/logo.png, /logo.png 1.5x, /logo.png 2x" data-sizes=auto alt=/logo.png title=/logo.png></a></div><div class=menu><div class=menu-inner><ul class=menu__list><li class=menu__item><a class=menu-item href=/><span class=menu__text>Home</span></a></li><li class="menu__item menu__dropdown"><a class=menu-item href=/about/><span class=menu__text>About ▾</span></a><ul class=submenu__list><li class=menu__item><a class=menu-item href=/about/organisation/><span class=menu__text>Organisation</span></a></li><li class=menu__item><a class=menu-item href=/about/principles/><span class=menu__text>Principles</span></a></li><li class=menu__item><a class=menu-item href=/about/technologies/><span class=menu__text>Technologies</span></a></li><li class=menu__item><a class=menu-item href=/about/sample-collections/><span class=menu__text>Collections</span></a></li></ul></li><li class="menu__item menu__dropdown"><a class=menu-item href=/resources/><span class=menu__text>Resources ▾</span></a><ul class=submenu__list><li class=menu__item><a class=menu-item href=/resources/ldaca-resources/><span class=menu__text>LDaCA Resources</span></a></li><li class=menu__item><a class=menu-item href=/resources/general-resources/><span class=menu__text>General Resources</span></a></li><li class=menu__item><a class=menu-item href=/resources/user-guides/><span class=menu__text>User Guides</span></a></li><li class=menu__item><a class=menu-item href=/resources/glossary/><span class=menu__text>Glossary</span></a></li></ul></li><li class="menu__item menu__dropdown"><a class=menu-item href=/news/><span class=menu__text>News ▾</span></a><ul class=submenu__list><li class=menu__item><a class=menu-item href=/news/events/><span class=menu__text>Events</span></a></li><li class=menu__item><a class=menu-item href=/news/newsletter/><span class=menu__text>Newsletter</span></a></li><li class=menu__item><a class=menu-item href=/news/posts/><span class=menu__text>Blog</span></a></li><li class=menu__item><a class=menu-item href=/news/publications/><span class=menu__text>Publications</span></a></li></ul></li><li class=menu__item><a class=menu-item href=/contact/><span class=menu__text>Contact</span></a></li><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop>
<input type=text placeholder="Search titles or contents..." id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=Search><i class="fas fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=Clear><i class="fas fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i>
</span></span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme"><i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></ul></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title=LDaCA><img class="lazyload logo" src=/svg/loading.min.svg data-src=/logo.png data-srcset="/logo.png, /logo.png 1.5x, /logo.png 2x" data-sizes=auto alt=/logo.png title=/logo.png></a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder="Search titles or contents..." id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=Search><i class="fas fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=Clear><i class="fas fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>Cancel</a></div><a class=menu-item href=/ title>Home</a><a class=menu-item href=/about/ title>About ▾</a><a class=menu-item href=/resources/ title>Resources ▾</a><a class=menu-item href=/news/ title>News ▾</a><a class=menu-item href=/contact/ title>Contact</a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class="page single special"><h1 class="single-title animate__animated animate__pulse animate__faster">Data Management in Language Technology: A Case Study of Appen</h1><div class=content id=content><p>by <a href=https://orcid.org/0009-0006-2241-3377 title="Rosanna is a Senior Research Project Officer in the LDaCA team. She completed Honours in linguistics at Monash University studying morphology in Scandinavian languages and has previously worked as a linguist and project manager in language technology." target=_blank>Rosanna Smith</a></p><br><p>Founded in Sydney in 1996, <a href=https://www.appen.com/ target=_blank rel="noopener noreffer">Appen</a> is a technology company that collects and improves data for the purposes of training and developing machine learning and artificial intelligence systems. During my time at Appen, a significant part of my work involved a diverse range of projects for both automatic speech recognition (<a href=/resources/glossary/#asr title="Automatic Speech Recognition" target=_blank>ASR</a>) and text-to-speech (<a href=/resources/glossary/#tts title=Text-to-Speech target=_blank>TTS</a>) technologies, including <a href=/resources/glossary/#phonetic-transcription title="A representation of speech in terms of the sounds actually produced in specific instances, using a phonetic alphabet" target=_blank>phonetic transcription</a>, grapheme-to-phoneme or letter-to-sound (L2S) rule development, and part-of-speech (POS) annotation.</p><br><p>To break down these language technologies further, <a href=/resources/glossary/#asr title="Automatic Speech Recognition" target=_blank>ASR</a> enables computers to process human spoken language into readable text, allowing users to operate devices through speech or facilitate translation of that speech into other languages. Conversely, <a href=/resources/glossary/#tts title=Text-to-Speech target=_blank>TTS</a> generates an audio version of a written text. <a href=/resources/glossary/#tts title=Text-to-Speech target=_blank>TTS</a> can be used to improve accessibility, particularly for those with vision impairments or learning disabilities such as dyslexia.</p><br><p>Language technology relies heavily on good-quality data, and the table below illustrates just some of the processes used in Appen projects, with use cases they can be applied to.</p><br><table><thead><tr><th style=text-align:left>Process Type</th><th style=text-align:left>Description</th><th style=text-align:left>Example Use Case</th></tr></thead><tbody><tr><td style=text-align:left><a href=/resources/glossary/#phonetic-transcription title="A representation of speech in terms of the sounds actually produced in specific instances, using a phonetic alphabet" target=_blank>Phonetic Transcription</a></td><td style=text-align:left>The process of transcribing words in a <a href=/resources/glossary/#lexicon title="A list of forms in a language with associated information, such as meanings, pronunciations or word class assignments." target=_blank>lexicon</a> according to their sound (pronunciation lexicon), through the use of a phonetic alphabet such as the International Phonetic Alphabet (<a href=/resources/glossary/#ipa title="International Phonetic Alphabet" target=_blank>IPA</a>) or <a href=/resources/glossary/#x-sampa title="Extended Speech Assessment Methods Phonetic Alphabet" target=_blank>X-SAMPA</a> (a phonetic script that uses symbols all found on a standard keyboard, aiding in native-speaker transcription). Suprasegmental features such as stress, tone, vowel length, pitch accent and syllabification can also be encoded where relevant to the language.</td><td style=text-align:left><strong>Use in ASR:</strong><br>Appen developed language packs in 26 languages for the Intelligence Advanced Research Projects Activity (<a href=https://www.iarpa.gov/ target=_blank rel="noopener noreffer">IARPA</a>) Babel program, facilitating improvement in speech recognition performance for languages other than English which have very little transcribed data.<br>These projects generally have <a href=/resources/glossary/#data-collection title="A set of data collected under similar conditions and brought together in a shared framework." target=_blank>data collection</a>, <a href=/resources/glossary/#orthographic-transcription title="A transcription method that employs the standard spelling system of each target language." target=_blank>orthographic transcription</a> and <a href=/resources/glossary/#phonetic-transcription title="A representation of speech in terms of the sounds actually produced in specific instances, using a phonetic alphabet" target=_blank>phonetic transcription</a> components, the latter using <a href=/resources/glossary/#x-sampa title="Extended Speech Assessment Methods Phonetic Alphabet" target=_blank>X-SAMPA</a> annotation.<br><br><em>Further reading: <a href=https://www.iarpa.gov/research-programs/babel target=_blank rel="noopener noreffer">IARPA - Babel</a><br>Example dataset: <a href=https://doi.org/10.35111/hgpe-cp39 target=_blank rel="noopener noreffer">IARPA Babel Mongolian Language Pack</a></em><br><br><strong>Use in TTS:</strong><br>In collaboration with health service providers GuildLink and MedAdvisor, Appen produces <a href=/resources/glossary/#tts title=Text-to-Speech target=_blank>TTS</a> audio of Australian Consumer Medicine Information (CMI) documents. This audio is available at <a href=https://medsinfo.com.au/consumer-information/A-To-Z-Index target=_blank rel="noopener noreffer">medsinfo</a>.<br><br><em>Further reading: <a href=https://www.appen.com/case-studies/guildlink-makes-consumer-medicines-information-more-accessible target=_blank rel="noopener noreffer">GuildLink Makes Consumer Medicines Information More Accessible</a></em></td></tr><tr><td style=text-align:left>Grapheme-to-Phoneme or Letter-to-Sound (L2S) Rule Development</td><td style=text-align:left>A set of rules for a given language that map between orthography and pronunciation, used to generate <a href=/resources/glossary/#phonetic-transcription title="A representation of speech in terms of the sounds actually produced in specific instances, using a phonetic alphabet" target=_blank>phonetic transcriptions</a> from an input text. These rules can be both single and multi-letter mappings such as orthographic &lt;s> → <a href=/resources/glossary/#x-sampa title="Extended Speech Assessment Methods Phonetic Alphabet" target=_blank>X-SAMPA</a> /s/ and &lt;sh> → /S/ in English. The rules can refer to the surrounding environment which allows for alternative phonetic mappings based on the characters’ position in a word, surrounding morphemes, or other linguistic processes that impact pronunciation. For example, rules are implemented to specify when &lt;s> should be pronounced as /z/ as in ‘roses’ or as /s/ as in ‘sit’.<br>Suprasegmental features such as stress, tone, vowel length, pitch accent and syllabification may also be encoded, however, the accuracy of these in the output pronunciations depends on the given language and the extent to which these features are predictable from orthography alone.</td><td style=text-align:left>As was the case for the IARPA Babel program, one of the first steps in producing pronunciation lexicons involves running the wordlist through a language or dialect-specific L2S algorithm to generate hypothesised <a href=/resources/glossary/#x-sampa title="Extended Speech Assessment Methods Phonetic Alphabet" target=_blank>X-SAMPA</a> pronunciations of each word. For many of the 26 languages in Babel, these rules didn’t yet exist and had to be developed through research, consultation and iterative testing with native speaker linguists. The automated output is then checked and edited as needed by native speaker linguists. L2S rules may be further developed according to customised requirements, for example, additional pronunciation variants for dialectal, colloquial or fast speech on top of the canonical pronunciation.</td></tr><tr><td style=text-align:left>Part-of-Speech (POS) Annotation</td><td style=text-align:left>The process of annotating each word in a text with its grammatical part of speech, for example, <em>noun</em>, <em>verb</em>, depending both on the word’s definition and its context within the wider phrase or text. A defined set of labels is used according to the grammar of the language being annotated.<br>POS lexicons may be used in conjunction with pronunciation lexicons to further improve natural language processing models for both <a href=/resources/glossary/#asr title="Automatic Speech Recognition" target=_blank>ASR</a> and <a href=/resources/glossary/#tts title=Text-to-Speech target=_blank>TTS</a>. They also assist in named-entity recognition (<a href=/resources/glossary/#ner title="Named-Entity Recognition" target=_blank>NER</a>) for large <a href=/resources/glossary/#corpus title="A collection of real-life examples of language selected to be a fair representation of the language or a particular linguistic genre." target=_blank>corpora</a> in cases where proper nouns are given additional sub-tags such as person, organisation and location.</td><td style=text-align:left>In collaboration with <a href=https://larrakia.com/ target=_blank rel="noopener noreffer">Larrakia Nation</a>, Appen assisted in linking two databases (text and audio) that previously could only be accessed independently, and had minimal time alignment between the audio and Larrakia and English text. One of the components of this project involved reviewing the POS annotations in the database, through a series of automated and manual checks, to identify and correct genuine errors or inconsistencies in notation from the original field notes, so that these were not present in the final version.<br><br><em>Further reading: <a href=https://www.appen.com/case-studies/preserving-language-through-useable-data target=_blank rel="noopener noreffer">Preserving Language Through Useable Data and Phonetic Annotation</a></em></td></tr></tbody></table><br><p>In all projects, data management is an important factor, both throughout the life of the project, as well as following its completion. The latter is particularly important in cases where Appen retains the license to resell the datasets.</p><br><p>In this case study, I’ll look at both of these aspects, outlining some of the challenges of data management and how these are overcome at Appen.</p><br><h2 id=data-management-during-the-life-of-a-project>Data Management during the Life of a Project</h2><br><p>Due to the variety of services, data types and customisation capabilities provided by Appen, it is difficult to present a single standard approach to data management. Instead, I’ll focus on the processes that were developed for datasets that have both <a href=/resources/glossary/#orthographic-transcription title="A transcription method that employs the standard spelling system of each target language." target=_blank>orthographic</a> and <a href=/resources/glossary/#phonetic-transcription title="A representation of speech in terms of the sounds actually produced in specific instances, using a phonetic alphabet" target=_blank>phonetic transcription</a> components, also known as transcription and <a href=/resources/glossary/#lexicon title="A list of forms in a language with associated information, such as meanings, pronunciations or word class assignments." target=_blank>lexicon</a> multi-component projects. The basic procedure for these projects is outlined below:</p><br><ol><li><p>The client or project sponsor specifies the parameters for the dataset and its collection in consultation with Appen specialists.</p></li><li><p>Appen carries out data collection, usually in the form of conversational or scripted telephony, <a href=/resources/glossary/#voip title="Voice over Internet Protocol" target=_blank>VoIP</a> or microphone recordings with qualified participants from Appen&rsquo;s crowd of more than a million. Conversational data refers to spontaneous or unscripted natural speech on a variety of topics either over the telephone or with both participants in the same room, while for scripted data, participants read and respond to a set text of prompts, curated to facilitate topic, domain, keywords, key phrases and phonetic coverage. All participants are provided with a consent form explaining the purpose of the collection and how the data will be used, and only take part in the collection if they are happy and comfortable to do so, and if they sign the consent form. Personal data such as names are anonymised and sensitive personal data is not collected.</p></li><li><p>The audio data is then quality-checked to ensure it meets the requirements for the collection, including demographic balance, language and content, background noise levels, audio levels and recording duration.</p></li><li><p>The approved audio goes through some pre-processing steps to batch the data into smaller segments, then is orthographically transcribed by the transcription (TX) team. Timestamps are checked at this stage as well to ensure correct alignment of the audio and the transcribed text, and a variety of labels are added to capture speaker and non-speaker noise events (e.g. laugh, cough, background noise). Rigorous quality assurance processes are applied while the transcription is ongoing and on the resulting complete data set.</p></li></ol><br><body><div><img src=/data-management-appen/audio-transcription.png alt="Audio Transcription Interface" title="Audio Transcription Interface" height class=center_image><div style=text-align:center><b>Figure 1: Example of audio with transcription, batched and presented to transcribers in tool.</b><br>Image Source: Appen</div></div></body><br><body><div><img src=/data-management-appen/tx_example_ENI_ASR003.png alt="Audio Transcription Text File" title="Audio Transcription Text File" height class=center_image><div style=text-align:center><b>Figure 2: Example of the resulting transcription text file.</b><br>Image Source: Appen</div></div></body><br><ol start=5><li>A sorted list of unique word forms (e.g. &lsquo;house&rsquo;, &lsquo;houses&rsquo;) occurring in the dataset is created from the orthographically transcribed data and sent to the lexicon (LX) team, who work with a group of native speaker linguists to prepare <a href=/resources/glossary/#phonetic-transcription title="A representation of speech in terms of the sounds actually produced in specific instances, using a phonetic alphabet" target=_blank>phonetic transcriptions</a> of the words, either in <a href=/resources/glossary/#x-sampa title="Extended Speech Assessment Methods Phonetic Alphabet" target=_blank>X-SAMPA</a> or another phonetic script. If a POS lexicon is also required for the dataset, this is similarly created from the sorted list of unique word forms and checked by native speaker linguists.</li></ol><br><body><div><img src=/data-management-appen/hungarian_appenlex.png alt="Hungarian Pronunciation Lexicon" title="Hungarian Pronunciation Lexicon" height class=center_image><div style=text-align:center><b>Figure 3: Example of a Hungarian pronunciation lexicon loaded to the transcription tool for native speaker review.</b><br>Image Source: Appen</div></div></body><br><body><div><img src=/data-management-appen/OTS_lex.jpg alt="UK English Pronunciation Lexicon" title="UK English Pronunciation Lexicon" height class=center_image><div style=text-align:center><b>Figure 4: Example of a UK English pronunciation lexicon.</b><br>Image Source: Appen</div></div></body><br><body><div><img src=/data-management-appen/POS_example_ENG_GBR.png alt="UK English POS Lexicon" title="UK English POS Lexicon" height class=center_image><div style=text-align:center><b>Figure 5: Example of a UK English POS lexicon.</b><br>Image Source: Appen</div></div></body><br><ol start=6><li><p>Data across each stage is validated for quality assurance.</p></li><li><p>The audio, transcription and lexicon(s) are packaged for delivery.</p></li></ol><br><p>As shown above, the data for a single project goes through multiple stages of annotation and requires specialist linguist expertise in the data management process before each part can be combined for final delivery.</p><br><p>One major challenge in this process is dealing with errors and inconsistencies that arise both prior to, and during, the validation stage, particularly where data is shared between the TX and LX teams. As transcribers and linguists prepare the annotations, variations may arise in features like spelling, capitalisation and punctuation. Languages may have no or multiple accepted orthographic conventions, and a standard approach must be determined for the project and adhered to. Conversely, other languages may already have standard orthographic conventions, but spelling or other errors may be introduced at one stage of transcription and identified at another stage.</p><br><p>Once a variation is identified and a decision on approach has been made, this change is applied to the whole of the transcription before an updated wordlist is prepared for the <a href=/resources/glossary/#lexicon title="A list of forms in a language with associated information, such as meanings, pronunciations or word class assignments." target=_blank>lexicon</a>. This spelling standardisation phase is inherently iterative and in order to reduce the number of iterations, robust processes were developed to automatically identify many of the variations and then track that the agreed final spelling forms were applied.</p><br><p>One example of these automated spelling standardisation processes is a <a href=/resources/glossary/#python title="A high-level, general-purpose programming language with an emphasis on code readability." target=_blank>Python</a> script run by the LX team which identifies entries with identical pronunciations but different orthographies in a lexicon. In some cases, these matches are expected (e.g. &lsquo;red&rsquo; and &lsquo;read&rsquo; in English would both have an <a href=/resources/glossary/#x-sampa title="Extended Speech Assessment Methods Phonetic Alphabet" target=_blank>X-SAMPA</a> transcription /" r E d/), while in other cases, it identifies either errors in spelling (e.g. &lsquo;colourr&rsquo;) or variation in need of standardisation (e.g. &lsquo;colour&rsquo;/&lsquo;color&rsquo;). The output of potential errors is reviewed by a native speaker and once legitimate inconsistencies are identified, these are sent back to the TX team so that they can be updated in the transcription data and a new wordlist generated for the lexicon. The process for making these updates is automated as much as possible but linguistic expertise is required at every stage to ensure the corrections are appropriately applied. This close collaboration of the teams responsible for the transcription and lexicon components is integral to producing high-quality speech databases with optimised data management practices.</p><br><h2 id=data-management-for-pre-labeled-datasets>Data Management for Pre-Labeled Datasets</h2><br><body><div><img src=/data-management-appen/pre-labeled-datasets.png alt="Pre-Labeled Datasets" title="Pre-Labeled Datasets" height class=center_image><div style=text-align:center><b>Figure 6: Visual representation of pre-labeled dataset types.</b><br>Image Source: Appen</div></div></body><br><p>At the time of writing, Appen has over 280 audio, image, video and text datasets in over 80 languages available as <a href=https://datasets.appen.com/ target=_blank rel="noopener noreffer">pre-labeled datasets</a>. These datasets are publicly accessible and can be filtered according to several categories: product type, common use cases, language and number of hours of audio, word or image count, if applicable (called Unit in the table below). Combined with a standard search function, this filtering allows interested parties to further refine their query for data most applicable to their needs.</p><br><table><thead><tr><th style=text-align:left>Product Type</th><th style=text-align:left>Common Use Cases</th><th style=text-align:left>Language</th><th style=text-align:left>Unit</th></tr></thead><tbody><tr><td style=text-align:left><ul><li>Audio<li>Image<li>Text<li>Video</td><td style=text-align:left><ul><li><a href=/resources/glossary/#asr title="Automatic Speech Recognition" target=_blank>ASR</a><li>Action Classification<li>Automatic Captioning<li>Baby Monitor<li>Call Centre<li>Chatbot<li>Content Classification<li>Conversational AI<li>Document Processing<li>Document Search<li>Facial Recognition<li>Fitness Applications<li>Gesture Recognition<li>In Car <a href=/resources/glossary/#hmi title="Human Machine Interface" target=_blank>HMI</a> & Entertainment<li>Keyword Spotting<li>Language Modelling<li><a href=/resources/glossary/#mt title="Machine Translation" target=_blank>MT</a><li><a href=/resources/glossary/#ner title="Named-Entity Recognition" target=_blank>NER</a><li>Search Engines<li>Security & Other Consumer Applications<li>Speech Analytics<li><a href=/resources/glossary/#tts title=Text-to-Speech target=_blank>TTS</a><li>Virtual Assistant</td><td style=text-align:left>A-Z</td><td style=text-align:left>A measure of the volume of the dataset, either in hours or word count.</td></tr></tbody></table><br><p>Each listing contains further details about the dataset, particularly in relation to aspects of the data collection, including the specifics of the language collected, the volume of the dataset, the number of contributors involved, recording conditions and the file formats available. Additional details appear in a pop-up window when you click on the &ldquo;tile&rdquo; for a given dataset. For example:</p><br><p><strong>Catalogue entries for a Danish POS dataset and a Mongolian pronunciation dictionary:</strong></p><br><body><div><img src=/data-management-appen/danish-combined.png alt="Danish POS Dictionary Catalogue Summary and Metadata" title="Danish POS Dictionary Catalogue Summary and Metadata" height class=center_image><div style=text-align:center><b>Figure 7: Danish POS dictionary catalogue summary and metadata.</b><br>Image Source: Appen</div></div></body><br><body><div><img src=/data-management-appen/mongolian-combined.png alt="Mongolian Pronunciation Dictionary Catalogue Summary and Metadata" title="Mongolian Pronunciation Dictionary Catalogue Summary and Metadata" height class=center_image><div style=text-align:center><b>Figure 8: Mongolian pronunciation dictionary catalogue summary and metadata.</b><br>Image Source: Appen</div></div></body><br><p>This is a helpful starting point for browsing and refining the dataset selection, but in order to find the most suitable match, clients consult directly with Appen to discuss their language technology needs in full.</p><br><p>More detailed <a href=/resources/glossary/#metadata title="The information that defines and describes data." target=_blank>metadata</a> for each dataset is tracked internally and this is used to further assist with client queries and requests. Some of the additional metadata categories recorded include the demographics of the contributors for each dataset, such as the age range and gender distribution of the participants, the dialect coverage within a specific language, the year of collection, and the domains or topics discussed in the collection.</p><br><p>Using the metadata as filters, requests can be divided into three alternative outcomes:</p><br><ol><li><p>Dataset(s) matching all requirements are available and a sample of the data is shared with the client to confirm this is the case.</p></li><li><p>Dataset(s) matching only some of the requirements are available and samples of these are shared in case they are still applicable to the project.</p></li><li><p>No dataset matching the requirements is available and a quote is then prepared for producing a new dataset ​​or enhancing an existing dataset.</p></li></ol><br><p>In terms of dataset storage, <a href=/resources/glossary/#collection title="A group of related Objects." target=_blank>collections</a> are catalogued first according to language and second by dataset type. This method works particularly well for pre-labeled datasets, because, if nothing else, clients usually know which language(s) they want data for and other specifics can follow from there.</p><br><h2 id=conclusions>Conclusions</h2><br><p>Both in cases where new datasets are being created and finalised <a href=/resources/glossary/#data-collection title="A set of data collected under similar conditions and brought together in a shared framework." target=_blank>collections</a> made ready for cataloguing, data management is a crucial consideration at Appen and, more broadly, any language technology project. Two main issues that are important to consider for data collections are:</p><br><ol><li><p>Ensuring that collections with multiple component parts are organised in such a way that updates can be applied to the whole, rather than introducing inconsistencies between related data.</p></li><li><p>Determining the parties that will be using the repository and assuring that the methods of accessing data are intuitive for all groups.</p></li></ol><br><p>These issues are handled in the Appen workflow through the use of iterative semi-automated spelling checks and other similar processes which enable modifications to be integrated into all levels of the dataset, and through clear recording and accessibility of the <a href=/resources/glossary/#metadata title="The information that defines and describes data." target=_blank>metadata</a> describing a collection, available both to Appen staff and its clients.</p><br><p>For <a href=/resources/glossary/#ldaca title="Language Data Commons of Australia" target=_blank>LDaCA</a>, these issues are of equal importance for wider data management. To the first point, while it is ultimately the responsibility and prerogative of the data contributor to decide how their data should be organised, LDaCA can also assist with this process. Guidance is available on best practices for data management and organisation of <a href=/resources/glossary/#metadata title="The information that defines and describes data." target=_blank>metadata</a>, both in the form of the documentation available at <a href=/resources/ldaca-resources/ rel>LDaCA Resources</a>, as well as automated validation of metadata category requirements for datasets added and edited through <a href=/resources/glossary/#crate-o title="A browser-based editor for RO-Crates." target=_blank>Crate-O</a>. To the second point, LDaCA has a responsibility to ensure that <a href=/resources/glossary/#tools title="Code or software developed to support or enhance (language) data accessibility and use." target=_blank>tools</a> to facilitate data management and discoverability are accessible and intuitive for all, including the portals that use the <a href=/resources/glossary/#oni title="A portal for discovery of RO-Crated data." target=_blank>Oni</a> application to access data packaged as <a href=/resources/glossary/#ro-crate title="Research Object Crate" target=_blank>RO-Crates</a>. This should be an iterative process, with further improvements to operability implemented based on user feedback and needs.</p><br></div><div><a onclick=history.back() class=banner-button>Go Back</a></div></div></div></main><br><br><div class=footer><div class=heading></div><br><div class=content><div class=about><h4><a href=/><img class=logo src=/logo.png height=120px></a></h4><br></div><div class=about><h4><a href=/about/>About</a></h4><p><a href=/about/organisation/>Organisation</a></p><p><a href=/about/principles/>Principles</a></p><p><a href=/about/technologies/>Technologies</a></p><p><a href=/about/sample-collections/>Collections</a></p></div><div class=resources><h4><a href=/resources/>Resources</a></h4><p><a href=/resources/ldaca-resources/>LDaCA Resources</a></p><p><a href=/resources/general-resources/>General Resources</a></p><p><a href=/resources/user-guides/>User Guides</a></p><p><a href=/resources/glossary/>Glossary</a></p></div><div class=news><h4><a href=/news/>News</a></h4><p><a href=/news/events/>Events</a></p><p><a href=/news/newsletter/>Newsletter</a></p><p><a href=/news/posts/>Blog</a></p><p><a href=/news/publications/>Publications</a></p></div><div class=contact><h4 class=address><a href=/contact/>Contact</a></h4><p><a href="https://ldaca.us13.list-manage.com/subscribe?u=ef8667be63aefb1e35062a797&id=de4b682e46">Subscribe to our newsletter.</a></p><p>Get in touch: <a href=mailto:ldaca@uq.edu.au>ldaca@uq.edu.au</a></p></div></div><div class=footer-line itemscope itemtype=http://schema.org/CreativeWork>Powered by <a href=https://gohugo.io/ target=_blank rel="noopener noreffer" title="Hugo 0.134.3">Hugo</a> | Theme - <a href=https://github.com/dillonzq/LoveIt target=_blank rel="noopener noreffer" title="LoveIt 0.2.11"><i class="far fa-kiss-wink-heart fa-fw" aria-hidden=true></i>
LoveIt. </a><i class="far fa-copyright fa-fw" aria-hidden=true></i><span itemprop=copyrightYear>2021 - 2024</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/ target=_blank>Language Data Commons of Australia</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by/4.0/ target=_blank>CC BY 4.0</a></span></div></div></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw" aria-hidden=true></i>
</a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw" aria-hidden=true></i></a></div><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css><script type=text/javascript src=https://cdn.jsdelivr.net/npm/autocomplete.js@0.38.1/dist/autocomplete.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lunr@2.3.9/lunr.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/copy-tex.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/mhchem.min.js></script><script type=text/javascript src=/mailchimp.js></script><script type=text/javascript src=/sender.js></script><script type=text/javascript src=/styling.js></script><script type=text/javascript src=https://platform.twitter.com/widgets.js></script><script type=text/javascript>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:50},comment:{},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{highlightTag:"em",lunrIndexURL:"/index.json",maxResultLength:10,noResultsFound:"No results found",snippetLength:30,type:"lunr"}}</script><script type=text/javascript src=/js/theme.min.js></script><script type=text/javascript>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-C3GSGXCYV6",{anonymize_ip:!0})</script><script type=text/javascript src="https://www.googletagmanager.com/gtag/js?id=G-C3GSGXCYV6" async></script></body></html>